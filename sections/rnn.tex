Traditional RNNs simulate a discrete-time system that has an input sequence \(\{x_1...x_t\}\) and a hidden state sequence \(\{h_1...h_t\}\) that map to an output sequence \(\{y_1...y_t\}\). The network is defined for timestep \(t\) in the sequence by the hidden and output equations:
\begin{equation}
	h_t = \Phi_h(W^Th_{t-1} + U^Tx_t + b_h)
\end{equation}
\begin{equation}
	y_t = \Phi_y(V^Th_t + b_y)
\end{equation}
where \(\Phi_h\) and \(\Phi_y\) are element-wise nonlinear functions and \(W\), \(U\), \(V\), \(b_h\), and \(b_y\) are the network parameters \(\Theta\). The hidden state \(h\) contains all information about the sequence for a given timestep \(t\).

RNNs can be trained via backpropagation over a set number of time steps, which is known as backpropagation through time. However, due to the exploding gradient problem, backpropagation through time has difficulty training the parameters for long-term temporal dependencies. To fix the exploding gradient problem, long short-term memory units (LSTM) \cite{lstm} can be introduced as the hidden units that contain extra parameters to learn a gated memory for storing the unit's activation value for a period of time steps. With this architecture, normal backpropagation through time can train the model to learn much longer temporal dependencies. Alternatively, Hessian-free optimization \cite{hessian_free} can learn the model parameters for long-term temporal dependencies without needing to introduce specialized hidden units.

\subsection{Extension to deep RNN}
